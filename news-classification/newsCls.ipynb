{
 "metadata": {
  "name": "",
  "signature": "sha256:78288779cf60f2474edca28b8817f54f375f55c68b63d1842a0fa7a84ed2435c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import re\n",
      "import regex\n",
      "import json\n",
      "import mysql.connector\n",
      "import pandas.io.sql as psql\n",
      "import urllib\n",
      "import boto\n",
      "import boto.s3.connection\n",
      "import pickle\n",
      "import jpype\n",
      "import re\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = mysql.connector.connect(\n",
      "host='security02-dev.datayes.com', db='mole_news', user='news_app_ro', passwd='YfuF6vTBaalJH2e')\n",
      "table_name = 'news_detail_backup'\n",
      "dateSt = '2014-04-01'\n",
      "dateEd = '2014-04-08'\n",
      "sql = 'select news_id, news_title,news_body,news_publish_time,main_related_company_id from %s where isActive = 1 and group_id != -1 and news_tag = 0 and source_type in (\"news_pgenius\") and news_publish_time > \"'+dateSt+'\" and news_publish_time < \"'+dateEd+'\";'\n",
      "newsdata = psql.read_sql(sql % table_name, db)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def n_gram_tokenizer(s):\n",
      "    res = []\n",
      "    for ind in range(len(s)-1):\n",
      "        res.append(s[ind:ind+2])\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace_name(news):\n",
      "    title = news.news_title\n",
      "    title = title.replace(u':','')\n",
      "    title = title.replace(u'\uff1a','')\n",
      "#     if news.main_related_company_id == -1:\n",
      "#         return title\n",
      "#     cpInfo = companyInfoMap[companyInfoMap[:,0]==news.main_related_company_id][0]\n",
      "#     name = cpInfo[2]\n",
      "#     stname = cpInfo[3]\n",
      "#     sttname = cpInfo[3][0:2]\n",
      "#     title = title.replace(name,'')\n",
      "#     title = title.replace(stname,'')\n",
      "#     title = title.replace(sttname,'')\n",
      "    return title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newsdata.news_title = newsdata.apply(replace_name, axis=1)\n",
      "titles = newsdata.news_title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(titles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(9867,)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse import *\n",
      "cv = CountVectorizer(analyzer=n_gram_tokenizer)\n",
      "cntContentRes = cv.fit_transform(titles)\n",
      "cntContentRes = cntContentRes.astype(int)\n",
      "wordsDF=pickle.load(file('titleWordsDf.ser'))\n",
      "feature = cv.get_feature_names();\n",
      "rep = cntContentRes.sum(axis=0).A[0]\n",
      "cntContentRes = cntContentRes[:,rep>1]\n",
      "feature = array(feature)[rep>1]\n",
      "wdDF_subset = []\n",
      "for wd in feature:\n",
      "    if wordsDF.has_key(wd):\n",
      "        wdDF_subset.append(wordsDF[wd])\n",
      "    else:\n",
      "        wdDF_subset.append(0)\n",
      "wdIdf = []\n",
      "maxDF = max(wdDF_subset)\n",
      "for x in wdDF_subset:\n",
      "    if x > 0:\n",
      "        wdIdf.append(log(maxDF/x))\n",
      "    else:\n",
      "        wdIdf.append(0)\n",
      "wdidfDia = lil_matrix((len(wdIdf),len(wdIdf)))\n",
      "wdidfDia.setdiag(wdIdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cntContentRes = cntContentRes.tocsr()\n",
      "idfVector = cntContentRes*wdidfDia"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filterMat = idfVector>0\n",
      "distMatJ = idfVector*filterMat.T\n",
      "JDia = 1/log(distMatJ.diagonal())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regMat = lil_matrix((len(JDia),len(JDia)))\n",
      "regMat.setdiag(JDia)\n",
      "distMatJ = distMatJ*regMat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import AffinityPropagation\n",
      "af = AffinityPropagation(affinity = 'precomputed',preference=2).fit(distMatJ.todense())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_centers_indices = af.cluster_centers_indices_\n",
      "labels = af.labels_\n",
      "res = pd.DataFrame({'title':titles.values, 'category': labels, 'center':0})\n",
      "\n",
      "for ind in cluster_centers_indices:\n",
      "    res['center'].ix[ind] = 1\n",
      "res = res.sort('category')\n",
      "res.to_csv('/root/data/classifyNewsTitle/clsResAllComp.txt',encoding = 'utf-8',sep = '\\t',index = False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import normalize\n",
      "idfVector = normalize(idfVector, norm='l2', axis=1, copy=False)\n",
      "distMat = idfVector*idfVector.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import squareform\n",
      "distMat = distMat.tolil()\n",
      "distMat.setdiag([1]*shape(distMat)[0])\n",
      "distMat = 1-distMat.todense()\n",
      "distMat[abs(distMat)< 0.0001] = 0.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.cluster.hierarchy import *\n",
      "distMatCondense = squareform(distMat)\n",
      "link = linkage(distMatCondense, method='weighted', metric='cosine')\n",
      "cluster = fcluster(link, 0.3, criterion='distance')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = pd.DataFrame({'title':titles.values, 'category': cluster})\n",
      "\n",
      "res = res.sort('category')\n",
      "res.to_csv('/root/data/classifyNewsTitle/pgeniusHirachicalday7Weighted.txt',encoding = 'utf-8',sep = '\\t',index = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}