{
 "metadata": {
  "name": "",
  "signature": "sha256:fb4d237b5dcc323d938f0513554206db18f4886baff80bda418bb8e57feaaf32"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import MySQLdb\n",
      "import pandas.io.sql as psql\n",
      "import pickle\n",
      "import re\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import random\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    conn=MySQLdb.connect(host='db-news01-dev.datayes.com',user='news_app',passwd='lKTOAIyoewzvCyc',db='news',port=3306,charset='utf8')\n",
      "    cur=conn.cursor()\n",
      "    cur.execute('select news_title from news_detail_backup where isActive = 1 and group_id != -1 and news_tag = 0 and news_publish_time > \"2013-01-01\";')\n",
      "    cur.close()\n",
      "    conn.close()\n",
      "except MySQLdb.Error,e:\n",
      "     print \"Mysql Error %d: %s\" % (e.args[0], e.args[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [elm[0] for elm in list(cur)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data=pd.read_pickle(\"news.ser\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #ansj segemnt\n",
      "# \"\"\"\n",
      "# wrapper for java tools\n",
      "\n",
      "# Run start_jvm with classpaths first, you must ensure all need jars are supplied\n",
      "# \"\"\"\n",
      "# import jpype\n",
      "# import os\n",
      "# class AnsjSplitter:\n",
      "#     \"\"\" Wrapper for ansj\n",
      "\n",
      "#     Needed jars:\n",
      "#     ansj_seg-xxx.jar\n",
      "#     tree_split-xxx.jar\n",
      "#     \"\"\"\n",
      "#     def __init__(self, dict_path=None):\n",
      "#         \"\"\" Parameters:\n",
      "#         dict_path: path of userLibrary\n",
      "#         \"\"\"\n",
      "#         self.AnsjConfig = jpype.JClass('org.ansj.util.MyStaticValue')\n",
      "#         self.AnsjConfig.ambiguityLibrary = None\n",
      "#         self.AnsjConfig.userLibrary = dict_path\n",
      "#         self.methods = {\n",
      "#             'base': jpype.JClass('org.ansj.splitWord.analysis.BaseAnalysis'),\n",
      "#             'to': jpype.JClass('org.ansj.splitWord.analysis.ToAnalysis'),\n",
      "#             'nlp': jpype.JClass('org.ansj.splitWord.analysis.NlpAnalysis'),\n",
      "#         }\n",
      "#         def split(self, txt, method = 'nlp'):\n",
      "#             \"\"\" split txt using method\n",
      "#             method can be \"base\", \"to\", or \"nlp\"\n",
      "#             \"\"\"\n",
      "#             if method not in self.methods:\n",
      "#                 raise RuntimeError('no such method for ansj')\n",
      "#             raw_res = self.methods[method].parse(txt).toArray()\n",
      "#             res = [(x.offe, x.offe+len(x.realName), x.nature.natureStr) for x in raw_res]\n",
      "#             return res\n",
      "\n",
      "# def start_jvm(class_path_list):\n",
      "#     \"\"\" Start jvm with class_path_list\n",
      "#     \"\"\"\n",
      "#     jpype.startJVM(jpype.getDefaultJVMPath(), '-ea', \"-Djava.class.path=%s\" % ':'.join(class_path_list))\n",
      "# def shutdown_jvm():\n",
      "#     \"\"\" shutdown jvm\n",
      "#     \"\"\"\n",
      "#     jpyte.shutdownJVM()\n",
      "# import glob\n",
      "# start_jvm(glob.glob('/root/jar_lib/*'))\n",
      "# ansj = AnsjSplitter('/root/data/userLibrary.txt')\n",
      "# def my_tokenizer(s):\n",
      "#     ll = ansj.split(s)\n",
      "#     res = []\n",
      "#     for tt in ll:\n",
      "#         res.append(s[tt[0]: tt[1]])\n",
      "#     return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def n_gram_tokenizer(s):\n",
      "    res = []\n",
      "    for ind in range(len(s)-1):\n",
      "        res.append(s[ind:ind+2])\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(analyzer=n_gram_tokenizer)\n",
      "cntContentRes = cv.fit_transform(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature = cv.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inverseFreq = cntContentRes.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inverseFreq = inverseFreq.sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inverseFreq.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "(1077533, 1)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inverseFreq==1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "matrix([[False],\n",
        "        [ True],\n",
        "        [False],\n",
        "        ..., \n",
        "        [False],\n",
        "        [False],\n",
        "        [False]], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordDf = dict(zip(cv.get_feature_names(),inverseFreq))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(wordDf,file('titleWordsDf.ser','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testLoad = pickle.load(file('titleWordsDf.ser','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pd.Series(cv.get_feature_names())[inverseFreq == 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#[inverseFreq[ind] for ind in inverseFreq.argsort()[0:400]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pd.Series(feature).ix[inverseFreq.argsort()>38000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}